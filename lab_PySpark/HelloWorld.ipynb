{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYSPARK_PYTHON\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexecutable\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      8\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mmaster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal[*]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      9\u001b[0m  \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparkHelloWorld\u001b[39m\u001b[38;5;124m'\u001b[39m) \\\n\u001b[1;32m     10\u001b[0m  \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    " .appName('SparkHelloWorld') \\\n",
    " .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+---+------+\n",
      "|firstname|middlename|lastname|   id|sex|salary|\n",
      "+---------+----------+--------+-----+---+------+\n",
      "|    James|          |   Smith|36636|  M|  3000|\n",
      "|  Michael|      Rose|        |40288|  M|    -1|\n",
      "|   Robert|          |Williams|42114|  M|  4000|\n",
      "|    Maria|      Anne|   Jones|39192|  F|  4000|\n",
      "|      Jen|      Mary|   Brown| null|  F|  3000|\n",
      "+---------+----------+--------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "data = [\n",
    " (\"James\", \"\", \"Smith\", \"36636\", \"M\", 3000),\n",
    " (\"Michael\", \"Rose\", \"\", \"40288\", \"M\", -1),\n",
    " (\"Robert\", \"\", \"Williams\", \"42114\", \"M\", 4000),\n",
    " (\"Maria\", \"Anne\", \"Jones\", \"39192\", \"F\", 4000),\n",
    " (\"Jen\", \"Mary\", \"Brown\", None, \"F\", 3000)\n",
    "]\n",
    "schema = StructType([\n",
    " StructField(\"firstname\", StringType(), True), \\\n",
    " StructField(\"middlename\", StringType(), True), \\\n",
    " StructField(\"lastname\", StringType(), True), \\\n",
    " StructField(\"id\", StringType(), True), \\\n",
    " StructField(\"sex\", StringType(), True), \\\n",
    " StructField(\"salary\", IntegerType(), True) \\\n",
    " ])\n",
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+---+------+\n",
      "|firstname|middlename|lastname|   id|sex|salary|\n",
      "+---------+----------+--------+-----+---+------+\n",
      "|    James|          |   Smith|36636|  M|  3000|\n",
      "|   Robert|          |Williams|42114|  M|  4000|\n",
      "|    Maria|      Anne|   Jones|39192|  F|  4000|\n",
      "+---------+----------+--------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_filtered = df.where(\n",
    "    (col(\"id\").isNotNull()) & (col(\"salary\") > 0)\n",
    ")\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+---+------+--------------+\n",
      "|firstname|middlename|lastname|   id|sex|salary|      fullname|\n",
      "+---------+----------+--------+-----+---+------+--------------+\n",
      "|    James|          |   Smith|36636|  M|  3000|    JamesSmith|\n",
      "|   Robert|          |Williams|42114|  M|  4000|RobertWilliams|\n",
      "|    Maria|      Anne|   Jones|39192|  F|  4000|MariaAnneJones|\n",
      "+---------+----------+--------+-----+---+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "df_full_name = df_filtered.withColumn(\n",
    " \"fullname\",\n",
    " concat(col(\"firstname\"), col(\"middlename\"), col(\"lastname\"))\n",
    ")\n",
    "df_full_name.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+---+------+----------------+\n",
      "|firstname|middlename|lastname|   id|sex|salary|        fullname|\n",
      "+---------+----------+--------+-----+---+------+----------------+\n",
      "|    James|          |   Smith|36636|  M|  3000|    James  Smith|\n",
      "|   Robert|          |Williams|42114|  M|  4000|Robert  Williams|\n",
      "|    Maria|      Anne|   Jones|39192|  F|  4000|Maria Anne Jones|\n",
      "+---------+----------+--------+-----+---+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "df_full_name2 = df_filtered.withColumn(\n",
    " \"fullname\",\n",
    " concat(\n",
    " col(\"firstname\"),\n",
    " lit(\" \"),\n",
    " col(\"middlename\"),\n",
    " lit(\" \"),\n",
    " col(\"lastname\"))\n",
    ")\n",
    "df_full_name2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+---+------+----------------+\n",
      "|firstname|middlename|lastname|   id|sex|salary|        fullname|\n",
      "+---------+----------+--------+-----+---+------+----------------+\n",
      "|    James|          |   Smith|36636|  M|  3000|     James Smith|\n",
      "|   Robert|          |Williams|42114|  M|  4000| Robert Williams|\n",
      "|    Maria|      Anne|   Jones|39192|  F|  4000|Maria Anne Jones|\n",
      "+---------+----------+--------+-----+---+------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.createOrReplaceTempView(\"df\")\n",
    "df_full_name3 = spark.sql(\"\"\"\n",
    " SELECT *,\n",
    " CASE\n",
    " WHEN middlename = '' THEN concat(firstname, \" \", lastname)\n",
    " ELSE concat(firstname, \" \", middlename, \" \", lastname)\n",
    " END AS fullname\n",
    " FROM df\n",
    "\"\"\")\n",
    "df_full_name3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+---+------+-----------------+\n",
      "|firstname|middlename|lastname|   id|sex|salary|         fullname|\n",
      "+---------+----------+--------+-----+---+------+-----------------+\n",
      "|    James|          |   Smith|36636|  M|  3000|      James Smith|\n",
      "|   Robert|          |Williams|42114|  M|  4000|  Robert Williams|\n",
      "|    Maria|      Anne|   Jones|39192|  F|  4000|Maria Jones Jones|\n",
      "+---------+----------+--------+-----+---+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df_full_name4 = df_filtered.withColumn(\n",
    " \"fullname\",\n",
    " when(\n",
    " col(\"middlename\") == \"\",\n",
    " concat(\n",
    " col(\"firstname\"),\n",
    " lit(\" \"),\n",
    " col(\"lastname\")\n",
    " )\n",
    " ).otherwise(\n",
    " concat(\n",
    " col(\"firstname\"),\n",
    " lit(\" \"),\n",
    " col(\"lastname\"),\n",
    " lit(\" \"),\n",
    " col(\"lastname\")\n",
    " )\n",
    " )\n",
    ")\n",
    "df_full_name4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
